import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
# Load the training dataset
train_df = pd.read_csv(r"C:\Users\sekha\Downloads\Disease_train.csv")
train_df.head()
# Check for missing values
missing_values = train_df.isnull().sum()
statistics = train_df.describe()
missing_values,statistics
# Standardize the feature columns
std_scaler = StandardScaler()
feature_columns = train_df.columns[1:-1] # Get feature columns explicitly
train_df[feature_columns] = std_scaler.fit_transform(train_df[feature_columns])
# Create box plots for each feature by diagnosis
for column in feature_columns:
 plt.figure(figsize=(10, 6))
 sns.boxplot(x='diagnosis', y=column, data=train_df)
 plt.title(f'Box Plot of {column} by Diagnosis')
 plt.show()
# Generate histograms for all features
train_df[feature_columns].hist(figsize=(15, 15), bins=20)
plt.suptitle('Histograms of All Features')
plt.show()
# Generate heat map for the features
df = train_df.drop(columns=['patient_id'])
plt.figure(figsize=(12, 8))
corr = df.corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix Heatmap')
plt.show()
# Separate features and target variable
X_features = train_df.drop(columns=['patient_id', 'diagnosis'])
y_target = train_df['diagnosis']
# Perform SMOTE to handle class imbalance
smote_resampler = SMOTE(random_state=42)
X_balanced, y_balanced = smote_resampler.fit_resample(X_features, y_target)
# Split the resampled data into training and validation sets
X_train_bal, X_val_bal, y_train_bal, y_val_bal = train_test_split(X_balanced,
y_balanced, test_size=0.2, random_state=42)
# Initialize the XGBoost classifier
xgb_classifier = XGBClassifier(random_state=42)
# Define the parameter grid for GridSearchCV
param_grid_search = {
 'n_estimators': [50, 100, 200],
 'max_depth': [3, 5, 7],
 'learning_rate': [0.1, 0.01, 0.001],
 'subsample': [0.6, 0.8, 1.0],
}
# Perform grid search with cross-validation to find the best parameters
grid_cv = GridSearchCV(xgb_classifier, param_grid_search, cv=5,
scoring='roc_auc', n_jobs=-1)
grid_cv.fit(X_train_bal, y_train_bal)
# Get the best estimator
optimal_xgb_classifier = grid_cv.best_estimator_
# ROC-AUC score on the training data
train_pred_prob = optimal_xgb_classifier.predict_proba(X_train_bal)[:, 1]
train_roc_auc_score = roc_auc_score(y_train_bal, train_pred_prob)
print(f"Training ROC-AUC Score: {train_roc_auc_score}")
# ROC-AUC score on the validation data
val_pred_prob = optimal_xgb_classifier.predict_proba(X_val_bal)[:, 1]
val_roc_auc_score = roc_auc_score(y_val_bal, val_pred_prob)
print(f"Validation ROC-AUC Score: {val_roc_auc_score}")
# Load and preprocess the test dataset
test_df = pd.read_csv(r"C:\Users\sekha\Downloads\Disease_test.csv")
test_df.iloc[:, 1:] = std_scaler.transform(test_df.iloc[:, 1:])
X_test_features = test_df.drop(columns=['patient_id'])
test_preds = optimal_xgb_classifier.predict(X_test_features)
# Save the test predictions along with patient IDs to a CSV file
student_identifier = 'SE22UCSE146'
predictions_output_df = pd.DataFrame({
 'patient_id': test_df['patient_id'],
 'prediction': test_preds
})
predictions_output_df.to_csv(f'student_{student_identifier}_predictions.csv',
index=False)
